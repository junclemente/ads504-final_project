{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ccc5ba0",
   "metadata": {},
   "source": [
    "# Modeling Notebook\n",
    "\n",
    "This notebook will be used to build and evaluate various classification models to predict whether a client will subscribe to a term deposit based on the preprocessed data In the previous notebook the output of the preprocessing were saved as artifacts. This notebook will load those artifacts and use them to train and evaluate the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892b7c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de61b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load artifacts from preprocessing notebook\n",
    "pipeline = joblib.load(\"artifacts/preprocessing_pipeline.joblib\")\n",
    "X_train_raw = joblib.load(\"artifacts/X_train_raw.joblib\")\n",
    "X_test_raw = joblib.load(\"artifacts/X_test_raw.joblib\")\n",
    "y_train = joblib.load(\"artifacts/y_train.joblib\")\n",
    "y_test = joblib.load(\"artifacts/y_test.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e1738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for modeling generator\n",
    "def make_pipeline(clf):\n",
    "    return ImbPipeline([\n",
    "        (\"preprocess\", pipeline),\n",
    "        (\"smote\", SMOTE(random_state=42)),\n",
    "        (\"classifier\", clf)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8305568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the models (classifiers)\n",
    "models = {\n",
    "    \"Perceptron\": Perceptron(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Support Vector Machine\": SVC(random_state=42, probability=True),\n",
    "    \"Neural Network\": MLPClassifier(random_state=42, max_iter=1000),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f158463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set scoring metrics\n",
    "scoring = [\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa764f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validate each model\n",
    "# initialize results dictionary\n",
    "avg_results = {}\n",
    "full_results = {}\n",
    "for name, clf in models.items():\n",
    "    pipe = make_pipeline(clf)\n",
    "    cv_results = cross_validate(pipe, X_train_raw, y_train_raw, cv=5, scoring=scoring, n_jobs=-1)\n",
    "    full_results[name] = {\n",
    "        \"fit_time\": cv_results[\"fit_time\"],\n",
    "        \"score_time\": cv_results[\"score_time\"],\n",
    "        \"test_accuracy\": cv_results[\"test_accuracy\"],\n",
    "        \"test_precision\": cv_results[\"test_precision\"],\n",
    "        \"test_recall\": cv_results[\"test_recall\"],\n",
    "        \"test_f1\": cv_results[\"test_f1\"],\n",
    "        \"test_roc_auc\": cv_results[\"test_roc_auc\"]}\n",
    "    avg_results[name] = {metric: np.mean(cv_results[f\"test_{metric}\"]) for metric in scoring}\n",
    "    avg_results[name].update({f\"std_{metric}\": np.std(cv_results[f\"test_{metric}\"]) for metric in scoring})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97809c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADS504",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
